# å¯¼å…¥å¿…è¦çš„åº“
import streamlit as st  # Streamlitç”¨äºåˆ›å»ºWebåº”ç”¨ç•Œé¢
import pandas as pd     # ç”¨äºæ•°æ®å¤„ç†å’Œåˆ†æ
import numpy as np      # ç”¨äºæ•°å€¼è®¡ç®—
import tensorflow as tf  # ç”¨äºåŠ è½½æ·±åº¦å­¦ä¹ æ¨¡å‹
import matplotlib.pyplot as plt  # ç”¨äºæ•°æ®å¯è§†åŒ–
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc  # ç”¨äºè®¡ç®—è¯„ä¼°æŒ‡æ ‡
from matplotlib import rcParams  # ç”¨äºè®¾ç½®matplotlibçš„å­—ä½“å’Œæ ·å¼

# é…ç½®matplotlibçš„æ˜¾ç¤ºå‚æ•°
rcParams['font.family'] = 'sans-serif'  # è®¾ç½®å­—ä½“
rcParams['font.size'] = 12              # è®¾ç½®å­—ä½“å¤§å°

# è®¾ç½®Streamlité¡µé¢é…ç½®
st.set_page_config(
    page_title="External Validation Analysis",  # é¡µé¢æ ‡é¢˜
    page_icon="ğŸ“Š",                            # é¡µé¢å›¾æ ‡
    layout="wide",                             # ä½¿ç”¨å®½å±å¸ƒå±€
    initial_sidebar_state="expanded"           # åˆå§‹ä¾§è¾¹æ çŠ¶æ€ä¸ºå±•å¼€
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {background-color: #f8f9fa;}  # ä¸»èƒŒæ™¯è‰²
    .stButton>button {background-color: #007bff; color: white; border-radius: 8px;}  # æŒ‰é’®æ ·å¼
    .metric-card {background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);}  # æŒ‡æ ‡å¡ç‰‡æ ·å¼
    h1 {color: #2c3e50; text-align: center;}  # æ ‡é¢˜æ ·å¼
    h2 {color: #34495e; border-bottom: 2px solid #17a2b8; padding-bottom: 5px;}  # äºŒçº§æ ‡é¢˜æ ·å¼
    </style>
""", unsafe_allow_html=True)

# é¡µé¢æ ‡é¢˜å’Œä»‹ç»
st.title("ğŸ“Š External Validation Analysis")
st.markdown("""
    æ­¤å·¥å…·ä½¿ç”¨ç‹¬ç«‹æ•°æ®é›†å¯¹é¢„æµ‹æ¨¡å‹è¿›è¡Œå¤–éƒ¨éªŒè¯ã€‚
    è®¡ç®—å…³é”®è¯„ä¼°æŒ‡æ ‡å¹¶ç”ŸæˆROCæ›²çº¿ä»¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚
""")

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹


@st.cache_resource
def load_model():
    """åŠ è½½é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹"""
    return tf.keras.models.load_model('data/MODEL_2025_05_16_19_37_41.h5')

# åŠ è½½éªŒè¯æ•°æ®


@st.cache_data
def load_validation_data():
    """åŠ è½½å¤–éƒ¨éªŒè¯æ•°æ®é›†"""
    df = pd.read_excel('data/merge_external_validation.xlsx')
    return df.iloc[:, :-2], df.iloc[:, -1]

# è®¡ç®—è¯„ä¼°æŒ‡æ ‡çš„å‡½æ•°


def calculate_metrics(y_true, y_pred_proba, cutoff):
    """
    è®¡ç®—æ¨¡å‹æ€§èƒ½æŒ‡æ ‡

    å‚æ•°:
    y_true: çœŸå®æ ‡ç­¾
    y_pred_proba: é¢„æµ‹æ¦‚ç‡

    è¿”å›:
    metrics: åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
    fpr, tpr: ROCæ›²çº¿çš„å‡é˜³æ€§ç‡å’ŒçœŸé˜³æ€§ç‡
    roc_auc: ROCæ›²çº¿ä¸‹é¢ç§¯
    """
    # å°†æ¦‚ç‡è½¬æ¢ä¸ºé¢„æµ‹æ ‡ç­¾ï¼ˆé˜ˆå€¼cutoffï¼‰
    y_pred = (y_pred_proba >= cutoff).astype(int)

    # æ ¹æ®æ¨¡å‹çš„cutoffå€¼è®¡ç®—ROCæ›²çº¿
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    roc_auc = auc(fpr, tpr)

    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    metrics = {
        'AUC': roc_auc,  # AUC
        'Accuracy': accuracy_score(y_true, y_pred),    # å‡†ç¡®ç‡
        'Precision': precision_score(y_true, y_pred),  # ç²¾ç¡®ç‡
        'Recall': recall_score(y_true, y_pred),        # å¬å›ç‡
        'F1 Score': f1_score(y_true, y_pred),           # F1åˆ†æ•°
        'Cutoff': cutoff  # cutoff
    }

    return metrics, fpr, tpr, roc_auc, y_pred


# ä¸»ç¨‹åº
def main():
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    model = load_model()
    X_val, y_true = load_validation_data()
    cutoff = 0.587

    # ä¸»è¦å†…å®¹
    st.header("Model Performance Metrics")  # æ¨¡å‹æ€§èƒ½æŒ‡æ ‡

    # è¿›è¡Œé¢„æµ‹
    y_pred_proba = model.predict(X_val, verbose=0)

    # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œè®¡ç®—è¯„ä¼°æŒ‡æ ‡
    if y_true is not None:
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics, fpr, tpr, roc_auc, y_pred = calculate_metrics(y_true, y_pred_proba, cutoff)

        # åœ¨ç½‘æ ¼ä¸­æ˜¾ç¤ºæŒ‡æ ‡ï¼Œå¢åŠ auc,acc,precision,recall,f1,cutoff
        col1, col2, col3, col4, col5, col6 = st.columns(6)
        with col1:
            st.metric("AUC", f"{metrics['AUC']:.3f}")    # æ˜¾ç¤ºAUC
        with col2:
            st.metric("Accuracy", f"{metrics['Accuracy']:.3f}")    # æ˜¾ç¤ºå‡†ç¡®ç‡
        with col3:
            st.metric("Precision", f"{metrics['Precision']:.3f}")  # æ˜¾ç¤ºç²¾ç¡®ç‡
        with col4:
            st.metric("Recall", f"{metrics['Recall']:.3f}")        # æ˜¾ç¤ºå¬å›ç‡
        with col5:
            st.metric("F1 Score", f"{metrics['F1 Score']:.3f}")    # æ˜¾ç¤ºF1åˆ†æ•°
        with col6:
            st.metric("Cutoff", f"{cutoff:.3f}")    # æ˜¾ç¤ºcutoff
        # ç»˜åˆ¶ROCæ›²çº¿
        st.header("ROC Curve")
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.plot(fpr, tpr, color='darkorange', lw=2,
                label=f'ROC curve (AUC = {roc_auc:.3f})')  # ç»˜åˆ¶ROCæ›²çº¿
        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # ç»˜åˆ¶å¯¹è§’çº¿
        ax.set_xlim([0.0, 1.0])
        ax.set_ylim([0.0, 1.05])
        ax.set_xlabel('False Positive Rate')  # è®¾ç½®xè½´æ ‡ç­¾
        ax.set_ylabel('True Positive Rate')   # è®¾ç½®yè½´æ ‡ç­¾
        ax.set_title('External Validation ROC Curve')  # è®¾ç½®æ ‡é¢˜
        ax.legend(loc="lower right")  # æ·»åŠ å›¾ä¾‹
        st.pyplot(fig)

    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    st.header("Detailed Results")
    # åˆ›å»ºç»“æœæ•°æ®æ¡†
    results_df = pd.DataFrame({
        'True Label': y_true,  # çœŸå®æ ‡ç­¾
        'Predicted Label': y_pred.flatten(),  # é¢„æµ‹æ ‡ç­¾
        'Predicted Probability': y_pred_proba.flatten()  # é¢„æµ‹æ¦‚ç‡
    })

    st.dataframe(results_df)  # æ˜¾ç¤ºç»“æœè¡¨æ ¼

    # é¡µè„š
    st.markdown("---")
    st.markdown(
        f"External Validation Analysis | Updated: {pd.Timestamp.now().strftime('%Y-%m-%d')}")


if __name__ == "__main__":
    main()
